{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Clustering und Klassifikation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Trainingsdaten trainieren ein System, neue Datenpunkte korrekt zu bewerten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Supervised vs. Unsupervised\n",
    "\n",
    "Machine Learning Algorithmen lassen sich in zwei Klassen einteilen:\n",
    "- Überwachtes Lernen\n",
    "- Unüberwachtes Lernen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Machine Learning](ML.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Überwachtes Lernen** (supervised) liegt dann vor, wenn die Trainingsdaten mit Klassen annotiert sind: Jeder Datenpunkt gehört einer Klasse an. Es gibt eine genau definierte Anzahl an möglichen Klassen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Sunburn Data Set](sunburn.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dies ist ein Beispiel für **Klassifikation**: Gegeben der Daten für jede Person, gehört sie zur Klasse **\"Hat Sonnenbrand\"**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Von **Regression** spricht man, wenn das Ergebnis ein Wert auf einer **kontinuierlichen Skala** ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*Beispiel: Vorhersage von Mietpreisen nach Lage und Eigenschaften der Wohnung*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Unüberwachtes Lernen** (unsupervised) liegt dann vor, wenn die Trainingsdaten nicht annotiert sind. Das Ziel ist es, Datenpunkte nach ihren Eigenschaften zu Gruppen zusammenzufügen. Dabei kann es eine vordefinierte Menge von Gruppen/**Cluster** geben, muss es aber nicht."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Unüberwachtes Lernen versucht also **Strukturen** in Daten zu finden. Ähnliche Datenpunkte werden zu **Clustern** zusammengefasst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Clustering Data Example](clustering_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Beispiel für ein Datenset mit 3 Clustern:\n",
    "\n",
    "![Cluster Example](cluster_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-Means\n",
    "\n",
    "Unüberwachter Algorithmus, Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Grundidee**: Finde die Mitte der Cluster, indem iterativ immer bessere Mittelpunkte gefunden werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Erschaffen uns beispielhaft Daten mit fünf Clustern\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "X,y_true = make_blobs(n_samples = 500, n_features = 2, centers = 5, cluster_std = 1.5, random_state = 7)\n",
    "plt.scatter(X[:,0],X[:,1], s=10)\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters = 5)\n",
    "kmeans.fit(X)         # 'fit' trainiert das Modell mit den Trainingsdaten\n",
    "y = kmeans.predict(X) # y sind die vorhergesagten 'Klassen' - hier also Cluster\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "plt.clf()\n",
    "plt.scatter(X[:,0], X[:,1], c=y, s=10, cmap=\"viridis\")\n",
    "plt.scatter(centers[:,0], centers[:,1], c=\"black\", s=100, alpha=0.6)\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Der K-Means Algorithmus:\n",
    "```\n",
    "Given: Dataset of objects in a vector space\n",
    "Given: Number k of desired Clusters\n",
    "Given: Maximum number of iterations i_max\n",
    "---\n",
    "centroids = {new set of k random points}\n",
    "for i to i_max:\n",
    "    assign all data points to closest centroid\n",
    "    move centroids to the center of their assigned points\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![KMeans Example](kmeans_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Distanz\n",
    "\n",
    "Um die Datenpunkte dem **nächsten** Mittelpunkt zuzuordnen, müssen wir die Distanz ausrechnen können.\n",
    "Im $R^2$ nutzen wir hierfür die **Euklidische Distanz** zwischen zwei Punkten $p$ und $q$:\n",
    "\n",
    "\\begin{equation}\n",
    "d(p,q) = \\sqrt{(q_x - p_x)^2 + (q_y - p_y)^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Mittelpunkt\n",
    "Den Mittelpunkt einer Menge $P$ von Punkten erhalten wir, indem wir für jede Achse den **Mittelwert** ausrechnen. Im $R^2$:\n",
    "\n",
    "\\begin{equation}\n",
    "m(P) = (\\frac{P_{1_x} + P_{2_x} + ... + P_{n_x}}{|P|},\\frac{P_{1_y} + P_{2_y} + ... + P_{n_y}}{|P|})\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Implementation\n",
    "\n",
    "> Aufgabe: Vervollständige die folgende Implementation von KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class MyKMeans():\n",
    "    \n",
    "    def __init__(self,data):\n",
    "        \"\"\"self.data is a collection of 2D points\"\"\"\n",
    "        self.data = [(x,y) for x,y in data]\n",
    "    \n",
    "    def distance(self,p,q):\n",
    "        \"\"\"Computes the euclidean distance between two 2D points\"\"\"\n",
    "        return math.sqrt(((q[0]-p[0])**2) + ((q[1]-p[1])**2))\n",
    "    \n",
    "    def mean(self,P):\n",
    "        \"\"\"Computes the mean of a set of points P\"\"\"\n",
    "        return (sum((x for x,y in P)) / len(P) , sum((y for x,y in P)) / len(P))\n",
    "    \n",
    "    def run(self, k=2, num_iterations=1):\n",
    "        \"\"\"Returns a list of 2D cetroids and a mapping of data points -> predicted cluster ID\"\"\"\n",
    "        centroids = [(x,y) for x,y in make_blobs(n_samples = k, n_features = 2, centers = k, cluster_std = 0.0, random_state = k)[0]]\n",
    "        predictions = {p:None for p in self.data}\n",
    "        \n",
    "        for i in range(num_iterations):\n",
    "            # 1. Assign all points to their respective nearest centroids\n",
    "            for p in predictions.keys():\n",
    "                closest_centroid_no = -1\n",
    "                closest_distance = 1000000\n",
    "                for n,c in enumerate(centroids):\n",
    "                    d = self.distance(p,c)\n",
    "                    if d < closest_distance:\n",
    "                        closest_distance = d\n",
    "                        closest_centroid_no = n\n",
    "                predictions[p] = closest_centroid_no\n",
    "            # 2. Move centroids to the center of their point clouds\n",
    "            for i in range(k):\n",
    "                new_centroid = self.mean(list(filter(lambda x : predictions[x] == i, predictions.keys())))\n",
    "                centroids[i] = new_centroid\n",
    "        \n",
    "        return np.array(centroids), list(predictions.values())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def draw_it(centroids, y):\n",
    "    plt.clf()\n",
    "    plt.scatter(X[:,0], X[:,1], c=y, s=10, cmap=\"viridis\")\n",
    "    plt.scatter(centroids[:,0], centroids[:,1], c=\"black\", s=100, alpha=0.6)\n",
    "    plt.draw()\n",
    "\n",
    "mk = MyKMeans(X)\n",
    "centroids, y = mk.run(k=5,num_iterations=1)\n",
    "\n",
    "draw_it(centroids, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "centroids, y = mk.run(k=5,num_iterations=2)\n",
    "draw_it(centroids, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "centroids, y = mk.run(k=5,num_iterations=4)\n",
    "draw_it(centroids, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "centroids, y = mk.run(k=5,num_iterations=8)\n",
    "draw_it(centroids, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "centroids, y = mk.run(k=5,num_iterations=12)\n",
    "draw_it(centroids, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "centroids, y = mk.run(k=5,num_iterations=15)\n",
    "draw_it(centroids, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "centroids, y = mk.run(k=5,num_iterations=50)\n",
    "draw_it(centroids, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "centroids, y = mk.run(k=2,num_iterations=50)\n",
    "draw_it(centroids, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "centroids, y = mk.run(k=3,num_iterations=50)\n",
    "draw_it(centroids, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "centroids, y = mk.run(k=10,num_iterations=50)\n",
    "draw_it(centroids, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-Nearest-Neighbor\n",
    "\n",
    "Überwachter Algorithmus, Klassifikation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Grundidee**: Finde naheliegende, bekannte Datenpunkte, um neue Datenpunkte zu klassifizieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Grundannahme:\n",
    "\n",
    "Objekte der gleichen Klasse sind sich ähnlicher, als Objekte aus verschiedenen Klassen.\n",
    "\n",
    "-> Wir brauchen **Features** der Objekte, anhande derer wir sie vergleichen können"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-> Sind die Features Zahlenwerte, können wir die Objekte als **Vektoren** im Raum darstellen \\\n",
    "-> Ähnliche Objekte liegen dann räumlich nahe beisammen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![KNN Example](knn_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Der K-Nearest-Neighbours Algorithmus:\n",
    "```\n",
    "Given: Set D of already classified objects in a vector space\n",
    "Given: Number k of neighbours to consider\n",
    "Input: New data point x to classify\n",
    "---\n",
    "N = get k nearest neighbouring data points of x in D\n",
    "evaluate N to get predicted class of x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Hyperparameter\n",
    "\n",
    "- Wie groß muss k sein?\n",
    "- Wie wird die Klassifikationsentscheidung getroffen?\n",
    " - Mehrheitsentscheidung?\n",
    " - k kleiner machen, bis Eindeutigkeit?\n",
    " - ...?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![KNN Hyperparameters](knn_hyperparams.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Implementation\n",
    "\n",
    "> Aufgabe: Vervollständige die folgende Implementation von KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class KNN_Classifier():\n",
    "    def __init__(self, train_data):\n",
    "        \"\"\"train_data is a dictionary of classified of 2D points: (x,y) -> class ID \"\"\"\n",
    "        self.data = train_data\n",
    "        \n",
    "    def distance(self,p,q):\n",
    "        \"\"\"Computes the euclidean distance between two 2D points\"\"\"\n",
    "        return math.sqrt(((q[0]-p[0])**2) + ((q[1]-p[1])**2))\n",
    "    \n",
    "    def classify(self, k=1, input_point=None):\n",
    "        \"\"\"Returns the class ID of the predicted class\n",
    "           Also returns the distance to the *furthest* neighbor (this will be used to draw the image!)\n",
    "            - Will use majority vote to determine the class\n",
    "            - Will fall back to k' = k-1 on a draw\n",
    "        \"\"\"\n",
    "        # Get neighbors sorted by distance (ascending) [((x,y),c),...]\n",
    "        neighbors = sorted(self.data.items(), key=lambda x: self.distance(input_point,(x[0][0],x[0][1])))[:k]\n",
    "        furthest_neighbor_distance = self.distance(input_point, (neighbors[-1][0][0],neighbors[-1][0][1]))\n",
    "        # Count classes of neighbors\n",
    "        class_counts = dict()\n",
    "        for point,c in neighbors:\n",
    "            class_counts[c] = class_counts.get(c,0) + 1 # c:n\n",
    "        class_counts = sorted(class_counts.items(),key=lambda x: x[1], reverse=True) # (c,n)\n",
    "        print(\"Class counts (c,n): \",class_counts)\n",
    "        # Fallback on draw\n",
    "        if len(class_counts) > 1 and class_counts[0][1] == class_counts[1][1]:\n",
    "            print(\"Fallback to k =\", k-1)\n",
    "            return self.classify(k=k-1, input_point=input_point)\n",
    "        return class_counts[0][1], furthest_neighbor_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def draw_knn(input_point, y_true, furthest_neighbor_dist):\n",
    "    plt.clf()\n",
    "    plt.scatter(X[:,0], X[:,1], c=y_true, s=4, cmap=\"viridis\")\n",
    "    plt.scatter([point[0]], [point[1]], c=\"black\", s=4, alpha=1)\n",
    "    circle = plt.Circle(input_point,furthest_neighbor_dist,fill=False)\n",
    "    plt.gcf().gca().add_artist(circle)\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data = {(d[0],d[1]):c for d,c in zip(X,y)} # (x,y) -> ID\n",
    "classifier = KNN_Classifier(data)\n",
    "point = (-6,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "cls, dist = classifier.classify(k=1,input_point=point)\n",
    "draw_knn(point,y_true,dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "cls, dist = classifier.classify(k=2,input_point=point)\n",
    "draw_knn(point,y_true,dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "cls, dist = classifier.classify(k=3,input_point=point)\n",
    "draw_knn(point,y_true,dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "cls, dist = classifier.classify(k=10,input_point=point)\n",
    "draw_knn(point,y_true,dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "cls, dist = classifier.classify(k=150,input_point=point)\n",
    "draw_knn(point,y_true,dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
